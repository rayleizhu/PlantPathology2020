{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q efficientnet\n",
    "# !pip install opencv-python==3.4.2.17\n",
    "# !pip install opencv-contrib-python==3.4.2.17\n",
    "# !conda install tensorflow-gpu -y\n",
    "# !conda install keras=2.3.1 -y\n",
    "# !conda install pandas -y\n",
    "# !conda install tqdm -y\n",
    "# !conda install scikit-learn -y\n",
    "# !conda install plotly -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "import efficientnet.tfkeras as efn\n",
    "from keras.utils import plot_model\n",
    "import tensorflow.keras.layers as L\n",
    "from keras.utils import model_to_dot\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "\n",
    "# import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\n",
    "\n",
    "tqdm.pandas()\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD, NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn import cluster\n",
    "from joblib import parallel_backend, Parallel, delayed\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyZKLcDg2yRi"
   },
   "source": [
    "### Load the data and define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "mneU8D9bpnKS"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "SAMPLE_LEN = 100\n",
    "IMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\n",
    "TEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\n",
    "TRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\n",
    "SUB_PATH = \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n",
    "\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  device placement and hyperparameters <a id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPU or GPU detection\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    \n",
    "def seed_everything(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "SEED=2048\n",
    "seed_everything(SEED)\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "print(\"GPUs: {}\".format(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# # Data access\n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "# Configuration\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "VALIDATION_SIZE = 0.15\n",
    "IMAGE_SIZE = 400\n",
    "\n",
    "# multiprocessing\n",
    "N_JOBS=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image path and labels <a id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_path(st):\n",
    "    return IMAGE_PATH + st + '.jpg'\n",
    "\n",
    "test_paths = test_data.image_id.apply(format_path).values\n",
    "trainval_paths = train_data.image_id.apply(format_path).values\n",
    "\n",
    "trainval_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n",
    "\n",
    "train_paths, valid_paths, train_labels, valid_labels =\\\n",
    "train_test_split(trainval_paths, trainval_labels, test_size=VALIDATION_SIZE,\n",
    "                 random_state=SEED)\n",
    "\n",
    "print('train samples: ', len(train_paths))\n",
    "print('valid samples: ', len(valid_paths))\n",
    "print('test samples: ', len(test_paths))\n",
    "print('path example: ', train_paths[0])\n",
    "print('label example: ',  train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image loading<a id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMAGE_SIZE, IMAGE_SIZE)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "#     image = tf.cast(image, tf.float32) / 255.0\n",
    "# https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "# https://github.com/keras-team/keras-applications/blob/bc89834ed36935ab4a4994446e34ff81c0d8e1b7/keras_applications/imagenet_utils.py#L42\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "\n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  training history display<a id=\"2.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n",
    "    \"\"\"\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    #ax.set_ylim(0.28,1.05)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pipeline component by name <a id=\"2.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone(cnn='VGG16'):\n",
    "    assert cnn in ['ResNet101V2', 'VGG16', 'InceptionResNetV2', 'MobileNetV2']\n",
    "    if cnn == 'ResNet101V2':\n",
    "        backbone = tf.keras.applications.ResNet101V2(\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False)\n",
    "    if cnn == 'VGG16':\n",
    "        backbone = tf.keras.applications.VGG16(\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False)\n",
    "    if cnn == 'InceptionResNetV2':\n",
    "        backbone = tf.keras.applications.InceptionResNetV2(\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False)\n",
    "    if cnn == 'MobileNetV2':\n",
    "        backbone = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False)     \n",
    "    return backbone\n",
    " \n",
    "\n",
    "def get_classifier(name='linearSVM'):\n",
    "    if name == 'linearSVM':\n",
    "#         return LinearSVC(class_weight='balanced',\n",
    "#                              probability=True)\n",
    "        return SVC(kernel='linear',\n",
    "                   class_weight='balanced',\n",
    "                   probability=True)\n",
    "    if name == 'rbfSVM':\n",
    "        return SVC(kernel='rbf',\n",
    "                       class_weight='balanced',\n",
    "                       probability=True)\n",
    "    if name == 'LR':\n",
    "        return LogisticRegression()\n",
    "\n",
    "    \n",
    "def get_dim_reductor(name='PCA_128'):\n",
    "    method, n_components = name.split('_')\n",
    "    n_components = int(n_components)\n",
    "#     print(method, n_components)\n",
    "    if method == 'PCA':\n",
    "        return PCA(n_components=n_components)\n",
    "#         return KernelPCA(n_components=n_components)\n",
    "    \n",
    "    if method == 'KPCA':\n",
    "        return KernelPCA(kernel='rbf', n_components=n_components)\n",
    "    \n",
    "    if method == 'LSA':\n",
    "        return TruncatedSVD(n_components=n_components,\n",
    "                            random_state=SEED)\n",
    "    \n",
    "    if method == 'NMF':\n",
    "        return NMF(n_components=n_components)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset object  <a id=\"2.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((trainval_paths, trainval_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .shuffle(512)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "tf.data.Dataset\n",
    "    .from_tensor_slices((train_paths, train_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "train_dataset_1 = (\n",
    "tf.data.Dataset\n",
    "    .from_tensor_slices((train_paths, train_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(64)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((valid_paths, valid_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test_paths)\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create output directories  <a id=\"2.7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = '../output/best_models'\n",
    "submission_dir = '../output/submissions'\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "os.makedirs(submission_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end finetuned CNN <a id=\"3.3\"></a>\n",
    "\n",
    "CNNs to be finetuned:\n",
    "\n",
    "* ResNet101V2\n",
    "* VGG16\n",
    "* InceptionResNetV2\n",
    "* MobileNetV2\n",
    "\n",
    "The first three models are heavy architectures, while the last, MobileNetV2 has All available pretrained CNNs are here: [Module: tf.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 0.0001\n",
    "LR_MAX = 0.00005 * 8\n",
    "LR_MIN = 0.0001\n",
    "LR_RAMPUP_EPOCHS = 4\n",
    "LR_SUSTAIN_EPOCHS = 6\n",
    "LR_EXP_DECAY = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_ls = []\n",
    "\n",
    "for cnn in ['ResNet101V2', 'VGG16', 'InceptionResNetV2', 'MobileNetV2']:\n",
    "    print(f'Finitune {cnn}...')\n",
    "    record = OrderedDict()\n",
    "    \n",
    "    with strategy.scope():\n",
    "        # build model\n",
    "        backbone = get_backbone(cnn)\n",
    "        model =  tf.keras.Sequential([\n",
    "            backbone,\n",
    "            L.GlobalMaxPooling2D(),\n",
    "#             L.Dropout(0.3),\n",
    "            L.Dense(4, activation='softmax')\n",
    "            ])\n",
    "        model.compile(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics=['categorical_accuracy']\n",
    "            )\n",
    "        model.summary()\n",
    "        \n",
    "        \n",
    "        ckpt_path = os.path.join(ckpt_dir,\n",
    "                                 f'finetuned_{cnn}.h5')\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            ckpt_path,\n",
    "            verbose=1,\n",
    "            monitor='val_categorical_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='auto') \n",
    "\n",
    "        STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "        history = model.fit(\n",
    "            train_dataset, \n",
    "            epochs=EPOCHS, \n",
    "            callbacks=[lr_callback, checkpoint],\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            validation_data=valid_dataset\n",
    "            )\n",
    "        \n",
    "        # display training curves\n",
    "        display_training_curves(\n",
    "            history.history['loss'], \n",
    "            history.history['val_loss'], \n",
    "            'loss', 211)\n",
    "        display_training_curves(\n",
    "            history.history['categorical_accuracy'], \n",
    "            history.history['val_categorical_accuracy'], \n",
    "            'accuracy', 212)\n",
    "        plt.show()\n",
    "        \n",
    "        record['model'] = f'finetuned_{cnn}'\n",
    "        best_idx = np.argmax(history.history['val_categorical_accuracy'])\n",
    "        record['train_loss'] = history.history['loss'][best_idx]\n",
    "        record['valid_loss'] = history.history['val_loss'][best_idx]\n",
    "        record['train_acc'] = history.history['categorical_accuracy'][best_idx]\n",
    "        record['valid_acc'] = history.history['val_categorical_accuracy'][best_idx]\n",
    "        record_ls.append(record)\n",
    "        \n",
    "        # run testing with best model weights\n",
    "        model.load_weights(ckpt_path)\n",
    "        \n",
    "        print('record: ', record['valid_loss'], record['valid_acc'])\n",
    "#         val_loss, val_acc = model.evaluate(valid_dataset)\n",
    "#         print('confirmation: ', val_loss, val_acc)\n",
    "        \n",
    "        print('Start inference on test dataset.')\n",
    "        probs = model.predict(test_dataset, verbose=1)\n",
    "        sub.loc[:, 'healthy':] = probs\n",
    "        sub.to_csv(os.path.join(submission_dir, f'finetune_{cnn}.csv'), index=False)\n",
    "#         sub.head()\n",
    "    \n",
    "    # release memory\n",
    "    # https://forums.fast.ai/t/how-could-i-release-gpu-memory-of-keras/2023/19\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df =  pd.DataFrame(record_ls)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(report_df)\n",
    "    \n",
    "report_df.to_csv(os.path.join('../output', f'fintune_cnn_report.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compelling result is derived by end-to-end finetuning CNN. Can we do better by preprocessing input images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry finetuning CNNs after backgroud removal <a id=\"3.4\"></a>\n",
    "\n",
    "The background may distract disease detection and classification, so let's try if backgroud removal helps. Following [victorlouisdg's kernel](https://www.kaggle.com/victorlouisdg/plant-pathology-opencv-background-removal), I use [grabcut] to do this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_removed_img_dir = '../input/images_no_bg'\n",
    "os.makedirs(bg_removed_img_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing images using grabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_grabcut_mask(h, w):\n",
    "    mask = np.ones((h, w), np.uint8) * cv2.GC_PR_BGD\n",
    "    mask[h//4:3*h//4, w//4:3*w//4] = cv2.GC_PR_FGD\n",
    "    mask[2*h//5:3*h//5, 2*w//5:3*w//5] = cv2.GC_FGD\n",
    "    return mask\n",
    "\n",
    "plt.imshow(init_grabcut_mask(3*136, 3*205))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image):\n",
    "    h, w = image.shape[:2]\n",
    "    mask = init_grabcut_mask(h, w)\n",
    "    bgm = np.zeros((1, 65), np.float64)\n",
    "    fgm = np.zeros((1, 65), np.float64)\n",
    "    cv2.grabCut(image, mask, None, bgm, fgm, 1, cv2.GC_INIT_WITH_MASK)\n",
    "    mask_binary = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    result = cv2.bitwise_and(image, image, mask = mask_binary)\n",
    "#     add_contours(result, mask_binary) # optional, adds visualizations\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize samples\n",
    "\n",
    "num_show = 5\n",
    "\n",
    "rows, cols = (num_show, 2)\n",
    "axes_pad = 0.2\n",
    "fig_h = 4.0 * rows + axes_pad * (rows-1) \n",
    "fig_w = 4.0 * cols + axes_pad * (cols-1) \n",
    "fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(rows, cols), axes_pad=0.2)   \n",
    "\n",
    "for i, ax in enumerate(grid):\n",
    "    img_path = trainval_paths[i//2]\n",
    "    img = cv2.resize(cv2.imread(img_path), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    if i % 2 == 1:\n",
    "        img = remove_background(img)\n",
    "    ax.imshow(img[:, :, ::-1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in tqdm(trainval_paths):\n",
    "    img = cv2.resize(cv2.imread(img_path), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    nobg = remove_background(img)\n",
    "    cv2.imwrite(os.path.join(bg_removed_img_dir,\n",
    "                             os.path.basename(img_path)),\n",
    "               nobg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in tqdm(test_paths):\n",
    "    img = cv2.resize(cv2.imread(img_path), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    nobg = remove_background(img)\n",
    "    cv2.imwrite(os.path.join(bg_removed_img_dir,\n",
    "                             os.path.basename(img_path)),\n",
    "               nobg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_path_nobg(st):\n",
    "    return os.path.join(bg_removed_img_dir, st + '.jpg')\n",
    "\n",
    "test_paths_new = test_data.image_id.apply(format_path_nobg).values\n",
    "trainval_paths_new = train_data.image_id.apply(format_path_nobg).values\n",
    "\n",
    "trainval_labels_new = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n",
    "\n",
    "train_paths_new, valid_paths_new, train_labels_new, valid_labels_new =\\\n",
    "train_test_split(trainval_paths_new,\n",
    "                 trainval_labels_new,\n",
    "                 test_size=VALIDATION_SIZE,\n",
    "                 random_state=SEED)\n",
    "\n",
    "print('train samples: ', len(train_paths_new))\n",
    "print('valid samples: ', len(valid_paths_new))\n",
    "print('test samples: ', len(test_paths_new))\n",
    "print('path example: ', train_paths_new[0])\n",
    "print('label example: ',  train_labels_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_new = (\n",
    "tf.data.Dataset\n",
    "    .from_tensor_slices((train_paths_new, train_labels_new))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset_new = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((valid_paths_new, valid_labels_new))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset_new = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test_paths_new)\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_ls = []\n",
    "\n",
    "for cnn in ['ResNet101V2', 'VGG16', 'InceptionResNetV2', 'MobileNetV2']:\n",
    "    print(f'Finitune {cnn}...')\n",
    "    record = OrderedDict()\n",
    "    \n",
    "    with strategy.scope():\n",
    "        # build model\n",
    "        backbone = get_backbone(cnn)\n",
    "        model =  tf.keras.Sequential([\n",
    "            backbone,\n",
    "            L.GlobalMaxPooling2D(),\n",
    "#             L.Dropout(0.3),\n",
    "            L.Dense(4, activation='softmax')\n",
    "            ])\n",
    "        model.compile(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics=['categorical_accuracy']\n",
    "            )\n",
    "        model.summary()\n",
    "        \n",
    "        \n",
    "        ckpt_path = os.path.join(ckpt_dir,\n",
    "                                 f'finetuned_{cnn}_nobg.h5')\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            ckpt_path,\n",
    "            verbose=1,\n",
    "            monitor='val_categorical_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='auto') \n",
    "\n",
    "        STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "        history = model.fit(\n",
    "            train_dataset_new, \n",
    "            epochs=EPOCHS, \n",
    "            callbacks=[lr_callback, checkpoint],\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            validation_data=valid_dataset_new\n",
    "            )\n",
    "        \n",
    "        # display training curves\n",
    "        display_training_curves(\n",
    "            history.history['loss'], \n",
    "            history.history['val_loss'], \n",
    "            'loss', 211)\n",
    "        display_training_curves(\n",
    "            history.history['categorical_accuracy'], \n",
    "            history.history['val_categorical_accuracy'], \n",
    "            'accuracy', 212)\n",
    "        plt.show()\n",
    "        \n",
    "        record['model'] = f'finetuned_{cnn}_nobg'\n",
    "        best_idx = np.argmax(history.history['val_categorical_accuracy'])\n",
    "        record['train_loss'] = history.history['loss'][best_idx]\n",
    "        record['valid_loss'] = history.history['val_loss'][best_idx]\n",
    "        record['train_acc'] = history.history['categorical_accuracy'][best_idx]\n",
    "        record['valid_acc'] = history.history['val_categorical_accuracy'][best_idx]\n",
    "        record_ls.append(record)\n",
    "        \n",
    "        # run testing with best model weights\n",
    "        model.load_weights(ckpt_path)\n",
    "        \n",
    "        print('record: ', record['valid_loss'], record['valid_acc'])\n",
    "#         val_loss, val_acc = model.evaluate(valid_dataset)\n",
    "#         print('confirmation: ', val_loss, val_acc)\n",
    "        \n",
    "        print('Start inference on test dataset.')\n",
    "        probs = model.predict(test_dataset_new, verbose=1)\n",
    "        sub.loc[:, 'healthy':] = probs\n",
    "        sub.to_csv(os.path.join(submission_dir,\n",
    "                                f'finetune_{cnn}_nobg.csv'),\n",
    "                   index=False)\n",
    "#         sub.head()\n",
    "    \n",
    "    # release memory\n",
    "    # https://forums.fast.ai/t/how-could-i-release-gpu-memory-of-keras/2023/19\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df =  pd.DataFrame(record_ls)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(report_df)\n",
    "    \n",
    "report_df.to_csv(os.path.join('../output',\n",
    "                              f'fintune_cnn_nobg_report.csv'),\n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all models, the accuracy is slightly decreased comapared to no background removal scenario. But it seems the overfitting problem is eased for InceptionResNetV2, since the training accuracy and validation accuracy are very close. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling <a id=\"4\"></a>\n",
    "\n",
    "Ensembling involves the averaging of multiple prediction vectos to reduce errors and improve accuracy. Now, I will ensemble predictions from DenseNet and EfficientNet to (hopefully) produce better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_subs = ['finetune_MobileNetV2.csv',\n",
    "                 'finetune_ResNet101V2.csv',\n",
    "                 'finetune_InceptionResNetV2.csv'\n",
    "                 'finetuned_InceptionResNetV2_nobg.csv']\n",
    "\n",
    "sub = pd.read_csv(SUB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = 0\n",
    "cnt  = len(ensemble_subs)\n",
    "\n",
    "for sub_name in ensemble_subs:\n",
    "    df = pd.read_csv(os.path.join(submission_dir, sub_name))\n",
    "    prob = df.loc[:, 'healthy':].to_numpy()\n",
    "#     display(df)\n",
    "#     print(prob)\n",
    "    final += prob\n",
    "    \n",
    "final = final / cnt\n",
    "sub.loc[:, 'healthy':] = final\n",
    "\n",
    "sub.to_csv(os.path.join(submission_dir, 'ensemble.csv'),\n",
    "           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
